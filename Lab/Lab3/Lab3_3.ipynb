{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3-3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEifQpW83IcGjVUetTomY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeb2Binfang/2021CS-GY9223/blob/main/Lab/Lab3/Lab3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall the cyclical learning rate policy discussed in the class. The learning rate changes in a cyclical manner between lrmin and lrmax, which are hyperparameters that need to be specified. For this problem, you first need to read carefully the article referenced below as you will be making use of the code there (in Keras) and modifying it as needed. For those who want to work in Pytorch, there are open source implementations of this policy available which you can easily search for and build over them. You will work with the FashionMNIST dataset and MiniGoogLeNet (described in reference).\n",
        "\n",
        "1. Fix batch size to 64 and start with 10 candidate learning rates between $10^{−9}$ and $10^1$ and train your model for 5 epochs. Plot the training loss as a function of the learning rate. You should see a curve like Figure 3 in the reference below. From that figure identify the values of $lr_{min}$ and $lr_{max}$. (2)\n",
        "2. Use the cyclical learning rate policy (with exponential decay) and train your network using batch size 64 and $lr_{min}$ and $lr_{max}$ values obtained in part 1. Plot train/validation loss and accuracy curve (similar to Figure 4 in reference). (3)\n",
        "3. We want to test if increasing batch size for a fixed learning rate has the same effect as decreasing learning rate for fixed batch size. Fix learning rate to $lr_{max}$ and train your network starting with batch size 32 and incrementally going up to 16384 (in increments of a factor of 2; like 32, 64...). You can choose a step size (in terms of the number of iterations) to increment the batch size. If your GPU cannot handle large batch sizes, you need to employ an effective batch size approach as discussed in Lecture 3 to simulate large batches. Plot the training loss. Is the generalization of your final model similar or different from than cyclical learning rate policy? (10)\n",
        "\n",
        "*reference:*\n",
        "\n",
        "* Leslie N. Smith Cyclical Learning Rates for Training Neural Networks. Available at https://arxiv.org/abs/1506.01186.\n",
        "* Keras implementation of cyclical learning rate policy. Available at https://www.pyimagesearch.com/2019/08/05/keras-learning-rate-finder/"
      ],
      "metadata": {
        "id": "bPPul4ZQGBzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/clr_callback.py\n",
        "!wget https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/config.py\n",
        "!wget https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/learningratefinder.py\n",
        "!wget https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/minigooglenet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYX817wTJul7",
        "outputId": "ff7022d6-e55b-4156-90b0-2bc2f0613b0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-23 19:37:56--  https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/clr_callback.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4531 (4.4K) [text/plain]\n",
            "Saving to: ‘clr_callback.py’\n",
            "\n",
            "\rclr_callback.py       0%[                    ]       0  --.-KB/s               \rclr_callback.py     100%[===================>]   4.42K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-23 19:37:56 (27.8 MB/s) - ‘clr_callback.py’ saved [4531/4531]\n",
            "\n",
            "--2022-03-23 19:37:56--  https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/config.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 729 [text/plain]\n",
            "Saving to: ‘config.py’\n",
            "\n",
            "config.py           100%[===================>]     729  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-23 19:37:57 (32.1 MB/s) - ‘config.py’ saved [729/729]\n",
            "\n",
            "--2022-03-23 19:37:57--  https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/learningratefinder.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5458 (5.3K) [text/plain]\n",
            "Saving to: ‘learningratefinder.py’\n",
            "\n",
            "learningratefinder. 100%[===================>]   5.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-23 19:37:57 (46.7 MB/s) - ‘learningratefinder.py’ saved [5458/5458]\n",
            "\n",
            "--2022-03-23 19:37:57--  https://raw.githubusercontent.com/yeb2Binfang/ECE-GY9143HPML/main/Lab/Lab3/minigooglenet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3227 (3.2K) [text/plain]\n",
            "Saving to: ‘minigooglenet.py’\n",
            "\n",
            "minigooglenet.py    100%[===================>]   3.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-23 19:37:57 (26.9 MB/s) - ‘minigooglenet.py’ saved [3227/3227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aDp9TzqnF7MR"
      },
      "outputs": [],
      "source": [
        "%run clr_callback.py\n",
        "%run learningratefinder.py\n",
        "%run minigooglenet.py\n",
        "%run config.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdDzpZHgSPge",
        "outputId": "02d3eee0-6db8-45d0-a7bd-4b056f84e0d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 10960137122510355104\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11320098816\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 14346392346584322483\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import sys"
      ],
      "metadata": {
        "id": "PizEHnlAKTjq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-f\", \"--lr-find\", type=int, default=0,\n",
        "\thelp=\"whether or not to find optimal learning rate\")\n",
        "args = vars(ap.parse_args())"
      ],
      "metadata": {
        "id": "VzGAj1-fLGAE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the training and testing data\n",
        "print(\"[INFO] loading Fashion MNIST data...\")\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "# Fashion MNIST images are 28x28 but the network we will be training\n",
        "# is expecting 32x32 images\n",
        "trainX = np.array([cv2.resize(x, (32, 32)) for x in trainX])\n",
        "testX = np.array([cv2.resize(x, (32, 32)) for x in testX])\n",
        "# scale the pixel intensities to the range [0, 1]\n",
        "trainX = trainX.astype(\"float\") / 255.0\n",
        "testX = testX.astype(\"float\") / 255.0\n",
        "# reshape the data matrices to include a channel dimension (required\n",
        "# for training)\n",
        "trainX = trainX.reshape((trainX.shape[0], 32, 32, 1))\n",
        "testX = testX.reshape((testX.shape[0], 32, 32, 1))\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, horizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuZDnq-6LMOQ",
        "outputId": "68e452a5-34cf-4db5-e8e3-06c24ab67596"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading Fashion MNIST data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "Fix batch size to 64 and start with 10 candidate learning rates between $10^{−9}$ and $10^1$ and train your model for 5 epochs. Plot the training loss as a function of the learning rate. You should see a curve like Figure 3 in the reference below. From that figure identify the values of $lr_{min}$ and $lr_{max}$. (2)"
      ],
      "metadata": {
        "id": "IxVmtic1ME4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=MIN_LR, momentum=0.9)\n",
        "model = MiniGoogLeNet.build(width=32, height=32, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "stepSize = STEP_SIZE * (trainX.shape[0] // BATCH_SIZE)\n",
        "clr = CyclicLR(\n",
        "\tmode='triangular',\n",
        "\tbase_lr=1e-10,\n",
        "\tmax_lr=10,\n",
        "\tstep_size=10)\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\tx=aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] // BATCH_SIZE,\n",
        "\tepochs=5,\n",
        "\tcallbacks=[clr],\n",
        "\tverbose=1)\n",
        "# evaluate the network and show a classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=testX, batch_size=BATCH_SIZE)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=CLASSES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7MpBSHjLTRQ",
        "outputId": "c6b7dce9-b6fb-4d56-bcbf-b15c7af34eff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] compiling model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/5\n",
            "937/937 [==============================] - 114s 109ms/step - loss: 2.9927 - accuracy: 0.1005 - val_loss: 2.6956 - val_accuracy: 0.1000\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 100s 106ms/step - loss: 2.7266 - accuracy: 0.1003 - val_loss: 2.6691 - val_accuracy: 0.1000\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 104s 111ms/step - loss: 2.7906 - accuracy: 0.0995 - val_loss: 2.6049 - val_accuracy: 0.1000\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 105s 112ms/step - loss: 2.6812 - accuracy: 0.0995 - val_loss: 2.5209 - val_accuracy: 0.1000\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 100s 106ms/step - loss: 2.7864 - accuracy: 0.0997 - val_loss: 2.5354 - val_accuracy: 0.1000\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         top       0.00      0.00      0.00      1000\n",
            "     trouser       0.00      0.00      0.00      1000\n",
            "    pullover       0.00      0.00      0.00      1000\n",
            "       dress       0.00      0.00      0.00      1000\n",
            "        coat       0.00      0.00      0.00      1000\n",
            "      sandal       0.00      0.00      0.00      1000\n",
            "       shirt       0.00      0.00      0.00      1000\n",
            "     sneaker       0.00      0.00      0.00      1000\n",
            "         bag       0.10      1.00      0.18      1000\n",
            "  ankle boot       0.00      0.00      0.00      1000\n",
            "\n",
            "    accuracy                           0.10     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.10      0.02     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lrf = LearningRateFinder(model)\n",
        "lrf.find(\n",
        "\t\taug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
        "\t\t1e-10, 1e+1,\n",
        "\t\tstepsPerEpoch=np.ceil((len(trainX) / float(BATCH_SIZE))),\n",
        "\t\tbatchSize=BATCH_SIZE)\n",
        "\n",
        "\t# plot the loss for the various learning rates and save the\n",
        "\t# resulting plot to disk\n",
        "lrf.plot_loss()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "vR36L1BNLYmw",
        "outputId": "9b773c4a-b427-4920-830a-956243205039"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "938/938 [==============================] - 94s 100ms/step - loss: 8.3722 - accuracy: 0.1003\n",
            "Epoch 2/3\n",
            "938/938 [==============================] - 94s 100ms/step - loss: 8.2824 - accuracy: 0.1000\n",
            "Epoch 3/3\n",
            "938/938 [==============================] - 94s 101ms/step - loss: 3.1149 - accuracy: 0.1007\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "Use the cyclical learning rate policy (with exponential decay) and train your network using batch size 64 and $lr_{min}$ and $lr_{max}$ values obtained in part 1. Plot train/validation loss and accuracy curve (similar to Figure 4 in reference). (3)"
      ],
      "metadata": {
        "id": "VE3frVY-L8I-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_LR = 1e-3\n",
        "MAX_LR = 10\n",
        "\n",
        "# initialize the optimizer and model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = SGD(lr=MIN_LR, momentum=0.9)\n",
        "model = MiniGoogLeNet.build(width=32, height=32, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "stepSize = STEP_SIZE * (trainX.shape[0] // BATCH_SIZE)\n",
        "clr = CyclicLR(\n",
        "\tmode='triangular',\n",
        "\tbase_lr=MIN_LR,\n",
        "\tmax_lr=MAX_LR,\n",
        "\tstep_size=STEP_SIZE)\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\tx=aug.flow(trainX, trainY, batch_size=BATCH_SIZE),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] // BATCH_SIZE,\n",
        "\tepochs=5,\n",
        "\tcallbacks=[clr],\n",
        "\tverbose=1)\n",
        "# evaluate the network and show a classification report\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=testX, batch_size=BATCH_SIZE)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=CLASSES))"
      ],
      "metadata": {
        "id": "sVkFZ61NO21M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a plot that plots and saves the training history\n",
        "N = np.arange(0, 5)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "# plot the learning rate history\n",
        "N = np.arange(0, len(clr.history[\"lr\"]))\n",
        "plt.figure()\n",
        "plt.plot(N, clr.history[\"lr\"])\n",
        "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
        "plt.xlabel(\"Training Iterations\")\n",
        "plt.ylabel(\"Learning Rate\")"
      ],
      "metadata": {
        "id": "BVQ5YgaLO42c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QoE6T7IqO_Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3\n",
        "We want to test if increasing batch size for a fixed learning rate has the same effect as decreasing learning rate for fixed batch size. Fix learning rate to $lr_{max}$ and train your network starting with batch size 32 and incrementally going up to 16384 (in increments of a factor of 2; like 32, 64...). You can choose a step size (in terms of the number of iterations) to increment the batch size. If your GPU cannot handle large batch sizes, you need to employ an effective batch size approach as discussed in Lecture 3 to simulate large batches. Plot the training loss. Is the generalization of your final model similar or different from than cyclical learning rate policy? (10)"
      ],
      "metadata": {
        "id": "7szSTBLQO_jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vZ-lN6GXPB7O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}